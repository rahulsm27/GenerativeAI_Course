{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 28 Jan 2024\n",
    "# # Reserach paper to read\n",
    "# ULMfit\n",
    "# GPT\n",
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Data ingestion (Collection ) - \n",
    "scrappping\n",
    "\n",
    "# Data pre processing \n",
    "Cleaning\n",
    "    (lower caseStemming, lemmetization, tokenization, removing html url white space punctuation)\n",
    "    POS tagging\n",
    "    NER \n",
    "    chunking\n",
    "    conference resolution\n",
    "    emoji revmoal\n",
    "Encoding \n",
    "\n",
    "Embedding\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33312</th>\n",
       "      <td>The (DVD)movie \"The Tempest\", directed by Jack...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27915</th>\n",
       "      <td>I saw this movie considering this as a normal ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17901</th>\n",
       "      <td>I want to say the acting is bad, but I think i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9221</th>\n",
       "      <td>I didn't know what to expect when I rented thi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37393</th>\n",
       "      <td>Those who have given this production such a lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "33312  The (DVD)movie \"The Tempest\", directed by Jack...  negative\n",
       "27915  I saw this movie considering this as a normal ...  negative\n",
       "17901  I want to say the acting is bad, but I think i...  negative\n",
       "9221   I didn't know what to expect when I rented thi...  positive\n",
       "37393  Those who have given this production such a lo...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "1  A wonderful little production. <br /><br />The...\n",
       "2  I thought this was a wonderful way to spend ti..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[1:2,['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     positive\n",
       "2     positive\n",
       "3     negative\n",
       "4     positive\n",
       "5     positive\n",
       "6     positive\n",
       "7     negative\n",
       "8     negative\n",
       "9     positive\n",
       "10    negative\n",
       "11    negative\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1:12,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review']= data['review'].map(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_tag(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(\"\",text)\n",
    "\n",
    "data['review'] = data['review'].apply(remove_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.\n",
    "What is the primary objective of text preprocessing in the context of generative AI?\n",
    "\n",
    "The text preprocessing objective is to process the raw data and make it suitable for use in the Gen AI model. It involves processes like cleaning (removing stop words, white spaces, unwanted characters, punctuations, tags, making lower case), lemmatization, stemming, tokenization, pos, and ner tagging.\n",
    "\n",
    "2.\n",
    "How does tokenization contribute to text preprocessing in the context of generative AI?\n",
    "\n",
    "Tokenization is the process of breaking down a sentence or text into smaller units called tokens. These small units can be at the word level, sub-word level, or character level. Each gen AI has a specific method of tokenization. These tokens are then embedded as dense vectors for processing through the Gen AI model. We must use the same tokenization that was used during training when we use the LLM model for either fine-tuning or inference.\n",
    "\n",
    "3.\n",
    "Explain the concept of one-hot encoding and its relevance to text preprocessing in generative AI models.\n",
    "\n",
    "The text cannot be fed in the Gen AI model as it is. It needs to be converted to numerical format before being fed. One hot encoding is one of the many techniques to represent text in numerical form .\n",
    "\n",
    "\n",
    "In one hot encoding, we first tokenized the sentence/text. We build a vocabulary of unique tokens. We then use binary labels for each token where all labels are zero except for the one token that we need to represent. So let's say we have a vocabulary of 10000 words. We will use a vector of 10000 dimensions to represent each token.  The vector will have a value 1 only at the position which indicates the token and 0 elsewhere. The vector will be sparse.\n",
    "\n",
    "\n",
    "4. What is the role of word embedding in text preprocessing for generative AI? Provide an example.\n",
    "\n",
    "Word embeddings help in the dense representation of words along with other semantic meanings. Unlike one hot encoding which represents token using sparse vectors word embedding represents token using continuous vectors along takin semantic meaning into account. Popular word embedding algorithm include Word2Vec and Glove\n",
    "\n",
    "5.\n",
    "Discuss the importance of data cleaning and normalization in the context of text preprocessing for generative AI.\n",
    "Data cleaning helps to deal with noisy and raw data. It converts them to a format that can be easily processed by the model.  They also help to ensure that any biase or incomplete or wrong information is not passed to the model which is crucial for fairness.\n",
    "\n",
    "\n",
    "\n",
    "Normalization techniques help to standard the input text data. This increases the quality and consistency of the training data which leads to better output from mode.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6.\n",
    "How does the concept of n-grams contribute to improving the quality of generated text in generative AI models?\n",
    "\n",
    " N-grams are contiguous sequences of n items (words or characters) extracted from a given text. They help in capturing local context and prepare feature-rich vectors for the numerical representation of text compared to one hot encoding. We can use a higher order of n for capturing longer dependences. They help in the probabilistic modeling of a sequence of words in language modelling\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "7.\n",
    "What are the challenges involved in handling noisy or unstructured text data for generative AI models? Provide potential solutions.\n",
    "\n",
    "Noisy data poses the following challenges\n",
    "\n",
    "Unambiguity - Their meaning cannot be deciphered with confidence. Noise data could contain misspellings, abbreviations, incomplete text, slang etc. The tokenization and embedding technique will either handle it incorrectly or replace it with the unknown token.\n",
    "Unexpected output - IF not handled properly during pre-processing noisy data reduces model effectiveness in producing correct output\n",
    "\n",
    "\n",
    "Potential solution include\n",
    "\n",
    "Spell checker\n",
    "Train model to take into account common accepted abbreviation\n",
    "Context-driven imputation for incomplete text\n",
    "\n",
    "\n",
    "8. Explain the process of text lemmatization and its significance in text preprocessing for generative AI applications.\n",
    "Text lemmatization is the process of breaking down the text into root words.\n",
    "\n",
    "Lemmatization involves reducing words to their base or root form (lemma). For example:\"running\" becomes \"run\"\n",
    "\n",
    "\"better\" becomes \"good\"\n",
    "\"mice\" becomes \"mouse\"\n",
    "The lemma is derived based on the word's grammatical category (part of speech). \n",
    "Different lemmatization algorithms take into account the POS information to ensure accurate reduction to the base form.\n",
    "\n",
    "Natural Language Toolkit (NLTK) library in Python provides lemmatization technique\n",
    "\n",
    "\n",
    "\n",
    "9. Describe the role of recurrent neural networks (RNNs) in generative AI for text generation, and discuss their limitations.RNNs have connections that create cycles within the network\n",
    "\n",
    "RNNs have connections that create cycles within the network. RNN are mainly used for text processing. They carry the past state information into the future. This is possible through a hidden state that acts as a memory of RNN. However, the limitation of RNNs was they cannot carry information for long-range dependencies. To solve this limitation they were re-designed into LSTM and GRU architecture. However, LSTM and GRU also had computational and memory limitations. To solve this attention mechanism was designed which ultimately led to the development of Transformer architecture.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "10.\n",
    "Discuss the concept of sequence-to-sequence models in the context of generative AI for text generation tasks.\n",
    "\n",
    "Sequence-to-sequence models are used when the input and output are of different varying lengths. The length of input and output cannot be pre-determined and are also not the same. \n",
    "\n",
    "Many generative tasks fall under this category like text generation, question and answer, language translation, summarization etc.\n",
    "Encoder- decoder is a popular architecture that is used to model sequence-to-sequence models.\n",
    "\n",
    "\n",
    "11.\n",
    "What are the potential ethical considerations associated with using generative AI for text generation, and how can they be addressed?\n",
    "\n",
    "The content generated by the Gen AI application should\n",
    "\n",
    "Non-Toxic - It should not contain language that sounds offensive\n",
    "Non-biased and fair - It should not generate content amplifying any existing bias. \n",
    "Respect privacy - It should not divulge any sensitive or private information\n",
    "Non-harmful and legal- It should encourage any activity that can result in harm or is lawfully illegal.\n",
    "Helpful and honest - It should generate honest and helpful content to the end user, devoid of misinformation.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
